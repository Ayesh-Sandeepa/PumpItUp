{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pump it up_simple.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOVWAfzCkWx1QNyVdYNu6D5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayesh-Sandeepa/PumpItUp/blob/main/Pump_it_up_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLBVwO55htv0"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from category_encoders import TargetEncoder,OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#tr_encoder=TargetEncoder()\n",
        "oh_encoder=OneHotEncoder()\n",
        "lbl_encoder=LabelEncoder()\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns',None)\n",
        "\n",
        "train_values=pd.read_csv(\"Training set values.csv\")\n",
        "train_labels=pd.read_csv(\"Training set labels.csv\")\n",
        "train_labels[\"status_group\"]=pd.Series(lbl_encoder.fit_transform(train_labels[\"status_group\"]))\n",
        "\n",
        "train_values[\"LatLong\"]=train_values[\"longitude\"]*train_values[\"latitude\"]\n",
        "train_values=train_values.drop([\"latitude\",\"longitude\"], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "cats_target=[\"funder\",\"ward\",\"installer\",\"subvillage\",\"lga\",\"scheme_name\",\"construction_year\",\"region_code\",\"district_code\",\"water_quality\",\"quantity\",\"source\",\"waterpoint_type\",\"source_class\",\"extraction_type\",\"management\",\"payment_type\"]\n",
        "cats_oh=[\"basin\",\"scheme_management\",\"management_group\"]\n",
        "nums=[\"gps_height\",\"LatLong\",\"population\"]\n",
        "\n",
        "cats=[\"amount_tsh\",\"funder\",\"ward\",\"installer\",\"subvillage\",\"lga\",\"scheme_name\",\"construction_year\",\"region\",\"region_code\",\"district_code\",\"basin\",\"scheme_management\",\"management_group\",\"extraction_type\",\"management\",\"payment_type\",\"water_quality\",\"quantity\",\"source\",\"waterpoint_type\",\"source_class\",\"permit\",\"public_meeting\",\"wpt_name\",\"region\",\"extraction_type_group\",\"extraction_type_class\",\"quality_group\",\"source_type\",\"waterpoint_type_group\"]\n",
        "\n",
        "drop_cols=[\"date_recorded\",\"num_private\",\"recorded_by\",\"payment\",\"quantity_group\"]\n",
        "\n",
        "train_values[cats_target]=train_values[cats_target].fillna(\"missing\")\n",
        "train_values[cats_oh]=train_values[cats_oh].fillna(\"missing\")\n",
        "\n",
        "train_values[nums]=train_values[nums].fillna(train_values[nums].mean())\n"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1MIgtViXab5"
      },
      "source": [
        "train_values[\"permit\"]= train_values[\"permit\"].astype(str)\n",
        "train_values[\"public_meeting\"]= train_values[\"public_meeting\"].astype(str)\n",
        "train_permit.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8NACu8Q1d2n"
      },
      "source": [
        "#train_values.recorded_by.unique()\n",
        "\n",
        "#otp=pd.DataFrame(oh_encoder.fit_transform(train_values[cats_oh]))\n",
        "\n",
        "#train_values=train_values.drop(cats_oh,axis=1)\n",
        "#train_values=train_values.join(otp)\n",
        "\n",
        "for col in cats:\n",
        "    print (col)\n",
        "    train_values[col]=pd.Series(lbl_encoder.fit_transform(train_values[col]))\n",
        "\n",
        "train_values=train_values.drop(drop_cols,axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_values,train_labels, test_size=0.2, random_state=25)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = 200, n_jobs = -1)\n",
        "\n",
        "\n",
        "clf.fit(X_train, y_train[\"status_group\"])\n",
        "\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(clf.predict(X_test), y_test[\"status_group\"])\n",
        "print(\"Accuracy = \" + str(accuracy))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtTVl3huYW_C"
      },
      "source": [
        "clf.fit(train_values, train_labels[\"status_group\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MgAFcsjNYth"
      },
      "source": [
        "test_values=pd.read_csv(\"Testing set values.csv\")\n",
        "\n",
        "test_values[\"LatLong\"]=test_values[\"longitude\"]*test_values[\"latitude\"]\n",
        "test_values=test_values.drop([\"latitude\",\"longitude\"], axis=1)\n",
        "\n",
        "test_values[cats_target]=test_values[cats_target].fillna(\"missing\")\n",
        "test_values[cats_oh]=test_values[cats_oh].fillna(\"missing\")\n",
        "\n",
        "test_values[nums]=test_values[nums].fillna(test_values[nums].mean())\n",
        "\n",
        "\n",
        "test_values[\"permit\"]=test_values[\"permit\"].astype(str)\n",
        "test_values[\"public_meeting\"]=test_values[\"public_meeting\"].astype(str)"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDNFb7WxIPEC"
      },
      "source": [
        "\n",
        "#train_values.recorded_by.unique()\n",
        "\n",
        "#otp1=pd.DataFrame(oh_encoder.fit_transform(test_values[cats_oh]))\n",
        "\n",
        "#test_values=test_values.drop(cats_oh,axis=1)\n",
        "#test_values=test_values.join(otp)\n",
        "\n",
        "for col in cats:\n",
        "    print (col)\n",
        "    test_values[col]=pd.Series(lbl_encoder.fit_transform(test_values[col]))\n",
        "\n",
        "test_values=test_values.drop(drop_cols,axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz1cF_AlN716"
      },
      "source": [
        "# Prediction for test data\n",
        "prediction = clf.predict(test_values)\n",
        "\n",
        "status_group = [\"functional\", \"non functional\", \"functional needs repair\"]\n",
        "\n",
        "### Making submission file###\n",
        "# Dataframe as per submission format\n",
        "submission = pd.DataFrame({\n",
        "            \"id\": test_values[\"id\"],\n",
        "            \"status_group\": prediction\n",
        "        })\n",
        "for i in range(len(status_group)):\n",
        "    submission.loc[submission[\"status_group\"] == i, \"status_group\"] = status_group[i]\n",
        "\n",
        "\n",
        "# Store submission dataframe into file\n",
        "submission.to_csv(\"submissionII.csv\", index = False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvi6KZuTpR6_"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}